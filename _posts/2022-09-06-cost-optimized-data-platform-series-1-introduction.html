---
layout: post
title:  "Building a Scalable Cost Optimized Resilient Data Platform"
date:   2022-09-06 20:27:05 +0300
categories: ["Data Architecture","Data Platform"]
description : Introduction to a data platform components
excerpt : In this series of posts, I discuss the data architecture of a scalable cost optimized resilient data platform, the tooling (toys), the reasons for the choices for tooling, the alternatives to the chosen tooling and the different persona in the ecosystem
permalink: cost-optimized-data-platform-part-1.html
is_series: true
is_pinned: false
is_featured: true
series_title: "Deploying a Cost Optimized Resilient Data Platform"
---

<h3>{{ page.title | upcase }} </h3>
<p class="text-sm"> {{ page.date | date: '%b' }} {{ page.date | date: '%d' }}, {{ page.date | date: '%Y' }} </p>
<br>
<p>
    For any business running cloud native infrastructure, the infrastructure costs will increase as the business grows, and cost efficiency is always paramount.
</p>
<p>
    Data engineering requires a high level of autonomy, so as a data engineer you must have a firm grasp of the infrastructure on which your data pipelines run.</p>
<p>
    You should be able to design, build and operationalize a data platform, then secure and monitor the data processing systems running on it; and for this reason a "You Build
    it, You Run it!" approach for data engineers especially in startups is always encouraged.
</p>
<p>
    You should be able to troubleshoot issues within a pipeline without any reliance on a third party; the DevOps/Platform engineer might be too busy to be bothered about the
    intrinsic details of the "Spark Shuffle" process when setting up or making infrastructure decisions and this will have a direct influence on your pipeline performance, it
    could be either transient or manifest later
</p>
<p>
    If you ran this infrastructure, as a data engineer, one of your KPIs, in a finance perspective will be to keep these costs at a minimum while still meeting SLAs set by
    business
</p>
<h3>
    So how can we build a cost optimized but resilient data platform?
</h3>
<p>
    In this series of posts, I discuss the data architecture of a scalable cost optimized resilient data platform, the tooling (toys), the reasons for the choices for tooling, the
    alternatives to the chosen tooling and the different persona in the ecosystem
</p>

<p>
    <p>The entire platform infrastructure is managed by Infrastructure as Code (IaC), the choice for this being Terraform, and complete project will be shared at a GitHub repo
</p>
<p>
    A cloud-agnostic platform was paramount to this project to alleviate cloud lock-in concerns but were necessary cloud-native services where used.
</p>

<p>The overall architecture of the project can be found <a href="../assets/img/platform-architecture.png" data-lightbox="platform-architecture.png">click to view</a> or
    <a href="../assets/img/platform-architecture.png" download="platform-architecture">download link</a></p>